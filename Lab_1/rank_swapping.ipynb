{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"train_data.csv\"\n",
    "df1 = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare card id and ip id for plotting\n",
    "\n",
    "# 1.Card ID\n",
    "card_enc = LabelEncoder()\n",
    "card_enc.fit(df1['card_id'])\n",
    "df1['card_id'] = card_enc.transform(df1.card_id)\n",
    "\n",
    "# 2.IP ID\n",
    "ip_enc = LabelEncoder()\n",
    "ip_enc.fit(df1['ip_id'])\n",
    "df1['ip_id'] = ip_enc.transform(df1.ip_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = \"train_data.csv\"\n",
    "df1 = pd.read_csv(data)\n",
    "\n",
    "#Encoding, Cleaning the data\n",
    "df1.loc[df1['cardverificationcodesupplied'].isna(),'cardverificationcodesupplied'] = False\n",
    "df1.loc[df1['issuercountrycode'].isna(),'issuercountrycode'] = 'ZZ'\n",
    "df1.loc[df1['shoppercountrycode'].isna(),'shoppercountrycode'] = 'ZZ'\n",
    "\n",
    "#Feature Engineering\n",
    "df1['countries_equal'] = (df1['shoppercountrycode'] == df1['issuercountrycode'])\n",
    "df1.loc[df1['countries_equal'] == False,'countries_equal'] = 0\n",
    "df1.loc[df1['countries_equal'] == True,'countries_equal'] = 1\n",
    "\n",
    "def conv(row):\n",
    "    currency_dict = {\"BGN\": 1.9558, \"NZD\": 1.6805, \"ILS\": 4.0448, \"RUB\": 72.2099, \"CAD\": 1.5075, \"USD\": 1.1218,\n",
    "                     \"PHP\": 58.125, \"CHF\": 1.1437, \"ZAR\": 16.0224, \"AUD\": 1.5911, \"JPY\": 124.93, \"TRY\": 6.6913,\n",
    "                     \"HKD\": 8.8007, \"MYR\": 4.6314, \"THB\": 35.802, \"HRK\": 7.413, \"NOK\": 9.6678, \"IDR\": 15953.68,\n",
    "                     \"DKK\": 7.4646, \"CZK\": 25.659, \"HUF\": 322.97, \"GBP\": 0.86248, \"MXN\": 21.2829, \"KRW\": 1308.01,\n",
    "                     \"ISK\": 136.2, \"SGD\": 1.5263, \"BRL\": 4.405, \"PLN\": 4.2868, \"INR\": 78.0615, \"RON\": 4.7596,\n",
    "                     \"CNY\": 7.5541, \"SEK\": 10.635}\n",
    "    return row['amount'] / (currency_dict[row['currencycode']]*100)\n",
    "\n",
    "df1['amount_eur'] = df1.apply(lambda x: conv(x), axis=1)\n",
    "\n",
    "df1['accountcode'] = df1['accountcode'].apply(lambda x: re.sub('Account','',x))\n",
    "df1['accountcode_cc'] = 0\n",
    "df1.loc[(df1['accountcode'] == 'UK'),'accountcode_cc'] = 'GB'\n",
    "df1.loc[(df1['accountcode'] == 'Mexico'),'accountcode_cc'] = 'MX'\n",
    "df1.loc[(df1['accountcode'] == 'Sweden'),'accountcode_cc'] = 'SE'\n",
    "df1.loc[(df1['accountcode'] == 'APAC'),'accountcode_cc'] = 'APAC'\n",
    "\n",
    "df1.loc[df1['mail_id'].str.contains('na',case=False),'mail_id'] = 'email99999'\n",
    "\n",
    "df1.loc[df1['cvcresponsecode'] > 2,'cvcresponsecode'] = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000000/5000000 [01:05<00:00, 76434.36it/s]\n",
      "100%|██████████| 5000000/5000000 [01:00<00:00, 82286.91it/s]\n",
      "100%|██████████| 5000000/5000000 [00:51<00:00, 97809.92it/s] \n",
      "100%|██████████| 5000000/5000000 [00:46<00:00, 106495.25it/s]\n",
      "100%|██████████| 5000000/5000000 [00:45<00:00, 108971.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                               True\n",
      "issuercountrycode               False\n",
      "txvariantcode                    True\n",
      "bin                              True\n",
      "amount                          False\n",
      "currencycode                    False\n",
      "shoppercountrycode              False\n",
      "shopperinteraction               True\n",
      "cardverificationcodesupplied     True\n",
      "cvcresponsecode                  True\n",
      "accountcode                      True\n",
      "mail_id                          True\n",
      "ip_id                            True\n",
      "card_id                          True\n",
      "label                            True\n",
      "countries_equal                  True\n",
      "amount_eur                      False\n",
      "accountcode_cc                   True\n",
      "dtype: bool\n",
      "number of rows still the same:  8932\n"
     ]
    }
   ],
   "source": [
    "def rank_swapping(data_original, p, num_swaps, columns):\n",
    "    data = data_original.copy()\n",
    "    for i, column in enumerate(columns):\n",
    "        # Sort the data by a column\n",
    "        data = data.sort_values(data.columns[column])\n",
    "        data = data.to_numpy()\n",
    "        # Perform swaps on the selected column and within p rows of the randomly selected row\n",
    "        for _ in tqdm(range(num_swaps)):\n",
    "            # Get a random index to swap\n",
    "            swap_index1 = np.random.randint(0, len(data))\n",
    "            # Set a minimum and maximum index for the swapping\n",
    "            max_index = min(len(data), swap_index1 + p)\n",
    "            min_index = max(0, swap_index1 - p)\n",
    "\n",
    "            # Get a random index to swap within the min and max index\n",
    "            swap_index2 = np.random.randint(min_index, max_index)\n",
    "\n",
    "            #Swap the rows\n",
    "            temp = data[swap_index1][column]\n",
    "            data[swap_index1][column] = data[swap_index2][column]\n",
    "            data[swap_index2][column] = temp\n",
    "        # Turn the np array back into a pd data frame\n",
    "        data = pd.DataFrame(data, columns=data_original.columns)\n",
    "\n",
    "    # Return the order of rows to its original\n",
    "    data = data.sort_values(data.columns[0])\n",
    "    return data\n",
    "\n",
    "ranked_frame = rank_swapping(df1, 300, 5000000, [1, 4, 5, 6, 16])\n",
    "original_values = df1.to_numpy()\n",
    "print(np.equal(ranked_frame, original_values).all())\n",
    "same_rows = 0\n",
    "for i in range(len(ranked_frame)):\n",
    "    if np.equal(ranked_frame.to_numpy()[i], original_values[i]).all():\n",
    "        same_rows += 1\n",
    "print('number of rows still the same: ', same_rows)\n",
    "df1 = ranked_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "unique_issuer_cc = df1['issuercountrycode'].unique()\n",
    "unique_shopper_cc = df1['shoppercountrycode'].unique()\n",
    "both = np.append(unique_issuer_cc, unique_shopper_cc)\n",
    "df_countrycodes = pd.DataFrame(both)\n",
    "unique_codes = df_countrycodes[0].unique()\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(df1['issuercountrycode'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'issuercountrycode' column\n",
    "df2 = pd.DataFrame(y, columns=['issuercountrycode_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'issuercountrycode' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('issuercountrycode', axis=1), df2], axis=1)\n",
    "\n",
    "y = lb.fit_transform(df1['shoppercountrycode'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'issuercountrycode' column\n",
    "df2 = pd.DataFrame(y, columns=['shoppercountrycode_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'issuercountrycode' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('shoppercountrycode', axis=1), df2], axis=1)\n",
    "\n",
    "lb2 = LabelBinarizer()\n",
    "y = lb2.fit_transform(df1['txvariantcode'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'txvariantcode' column\n",
    "df2 = pd.DataFrame(y, columns=['txvariantcode_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'txvariantcode' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('txvariantcode', axis=1), df2], axis=1)\n",
    "\n",
    "lb3 = LabelBinarizer()\n",
    "y = lb3.fit_transform(df1['currencycode'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'currencycode' column\n",
    "df2 = pd.DataFrame(y, columns=['currencycode_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'currencycode' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('currencycode', axis=1), df2], axis=1)\n",
    "\n",
    "lb4 = LabelBinarizer()\n",
    "y = lb4.fit_transform(df1['shopperinteraction'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'shopperinteraction' column\n",
    "df2 = pd.DataFrame(y, columns=['shopperinteraction_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'shopperinteraction' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('shopperinteraction', axis=1), df2], axis=1)\n",
    "\n",
    "lb5 = LabelBinarizer()\n",
    "y = lb5.fit_transform(df1['accountcode_cc'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'accountcode_cc' column\n",
    "df2 = pd.DataFrame(y, columns=['accountcode_cc_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'accountcode_cc' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('accountcode_cc', axis=1), df2], axis=1)\n",
    "\n",
    "# drop id, mail_id, ip_id, card_id\n",
    "df1 = df1.drop(['Id','mail_id','ip_id','card_id', 'amount', 'accountcode'], axis=1)\n",
    "\n",
    "processed_df1 = df1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1  of  10\n",
      "round  2  of  10\n",
      "round  3  of  10\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X = df1.drop('label', axis=1)\n",
    "y = df1['label']\n",
    "\n",
    "y = y.astype('int')\n",
    "\n",
    "# Define the number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store the predictions, probability and truth\n",
    "y_proba_all_dec_tree = []\n",
    "y_predicts_all_dec_tree = []\n",
    "y_truth_all_dec_tree = []\n",
    "\n",
    "y_proba_all_mlp = []\n",
    "y_predicts_all_mlp = []\n",
    "y_truth_all_mlp = []\n",
    "\n",
    "y_proba_all_log = []\n",
    "y_predicts_all_log = []\n",
    "y_truth_all_log = []\n",
    "\n",
    "round_counter = 0\n",
    "# Iterate through the folds\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    round_counter += 1\n",
    "    print('round ', round_counter, ' of ', n_splits)\n",
    "    # Split the data into training and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create and train the Decision Tree Classifier\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba_all_dec_tree.extend(y_proba)\n",
    "    y_predicts_all_dec_tree.extend(y_pred)\n",
    "    y_truth_all_dec_tree.extend(y_test)\n",
    "\n",
    "    # use a neural network for classification\n",
    "    # Create and train the Multi-Layer Perceptron Classifier\n",
    "    clf = MLPClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba_all_mlp.extend(y_proba)\n",
    "    y_predicts_all_mlp.extend(y_pred)\n",
    "    y_truth_all_mlp.extend(y_test)\n",
    "\n",
    "    # Create a logistic regression object\n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    # Fit the model using the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba_all_log.extend(y_proba)\n",
    "    y_predicts_all_log.extend(y_pred)\n",
    "    y_truth_all_log.extend(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate confusion_mat score\n",
    "confusion_mat_dec_tree = confusion_matrix(y_truth_all_dec_tree, y_predicts_all_dec_tree)\n",
    "\n",
    "# Print the confusion_mat score\n",
    "print(\"confusion_mat score decision tree:\")\n",
    "print(confusion_mat_dec_tree)\n",
    "\n",
    "# Calculate confusion_mat score\n",
    "confusion_mat_mlp = confusion_matrix(y_truth_all_mlp, y_predicts_all_mlp)\n",
    "\n",
    "# Print the confusion_mat score\n",
    "print(\"confusion_mat score mlp:\")\n",
    "print(confusion_mat_mlp)\n",
    "\n",
    "# Calculate confusion_mat score\n",
    "confusion_mat_log = confusion_matrix(y_truth_all_log, y_predicts_all_log)\n",
    "\n",
    "# Print the confusion_mat score\n",
    "print(\"confusion_mat score logistic regression:\")\n",
    "print(confusion_mat_log)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the probability of being a fraud transaction for every sample\n",
    "one_prob_dec_tree = [lst[1] for lst in y_proba_all_dec_tree]\n",
    "fpr, tpr, thresholds = roc_curve(y_truth_all_dec_tree, one_prob_dec_tree)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random Guess')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Decision Tree')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Get the probability of being a fraud transaction for every sample\n",
    "one_prob_mlp = [lst[1] for lst in y_proba_all_mlp]\n",
    "fpr, tpr, thresholds = roc_curve(y_truth_all_mlp, one_prob_mlp)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random Guess')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic MLP')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Get the probability of being a fraud transaction for every sample\n",
    "one_prob_log = [lst[1] for lst in y_proba_all_log]\n",
    "fpr, tpr, thresholds = roc_curve(y_truth_all_log, one_prob_log)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random Guess')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Logistic Regression')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3b. Analyse the performance of the classifiers. Explain which method performs best."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ROC curves do not tell us much for the decision three and MLP. This is because a decision three does not give probabilities other than 0 and 1. Basically there are 3 different thresholds for classifying: t<0 (all cases are fraud cases), 0<t<1 cases are fraud or not based on the decision tree and t>1 no fraud cases at all. Because the data is so imbalanced, the MLP has learned to classify all cases as normal transactions. This gives two points on the ROC curve: either all are fraud or all are normal. This gives the same line as a random guess.\n",
    "\n",
    "The logistic regression does give probabilities and therefor has a useful ROC curve.\n",
    "\n",
    "The classifiers perform almost exactly the same on the data before and after rank swapping. In terms of accuracy, the MLP and logistic regression perform the best. They however only classify three samples as fraud and those are not actually fraud cases. The decision three does pick some fraud cases correctly and is therefor the most useful."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3c. Can you explain the performance difference for the different classifiers? Is it advisable to protect people’s privacy using rank-swapping? Why (not)?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
