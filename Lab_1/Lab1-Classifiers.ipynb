{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import nbformat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"train_data.csv\"\n",
    "df1 = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"train_data.csv\"\n",
    "df1 = pd.read_csv(data)\n",
    "\n",
    "#Prepare card id and ip id for plotting\n",
    "\n",
    "# # 1.Card ID\n",
    "# card_enc = LabelBinarizer()\n",
    "# df1['card_id'] = card_enc.fit_transform(df1[])\n",
    "\n",
    "#\n",
    "# # 2.IP ID\n",
    "# ip_enc = LabelBinarizer()\n",
    "# df1['ip_id'] = ip_enc.fit_transform(df1.ip_id)\n",
    "\n",
    "#Encoding, Cleaning the data\n",
    "df1.loc[df1['cardverificationcodesupplied'].isna(),'cardverificationcodesupplied'] = False\n",
    "df1.loc[df1['issuercountrycode'].isna(),'issuercountrycode'] = 'ZZ'\n",
    "df1.loc[df1['shoppercountrycode'].isna(),'shoppercountrycode'] = 'ZZ'\n",
    "\n",
    "#Feature Engineering\n",
    "df1['countries_equal'] = (df1['shoppercountrycode'] == df1['issuercountrycode'])\n",
    "df1.loc[df1['countries_equal'] == False,'countries_equal'] = 0\n",
    "df1.loc[df1['countries_equal'] == True,'countries_equal'] = 1\n",
    "\n",
    "unique_issuer_cc = df1['issuercountrycode'].unique()\n",
    "unique_shopper_cc = df1['shoppercountrycode'].unique()\n",
    "both = np.append(unique_issuer_cc, unique_shopper_cc)\n",
    "df_countrycodes = pd.DataFrame(both)\n",
    "unique_codes = df_countrycodes[0].unique()\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(df1['issuercountrycode'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'issuercountrycode' column\n",
    "df2 = pd.DataFrame(y, columns=['issuercountrycode_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'issuercountrycode' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('issuercountrycode', axis=1), df2], axis=1)\n",
    "\n",
    "y = lb.fit_transform(df1['shoppercountrycode'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'issuercountrycode' column\n",
    "df2 = pd.DataFrame(y, columns=['shoppercountrycode_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'issuercountrycode' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('shoppercountrycode', axis=1), df2], axis=1)\n",
    "\n",
    "def conv(row):\n",
    "    currency_dict = {\"BGN\": 1.9558, \"NZD\": 1.6805, \"ILS\": 4.0448, \"RUB\": 72.2099, \"CAD\": 1.5075, \"USD\": 1.1218,\n",
    "                     \"PHP\": 58.125, \"CHF\": 1.1437, \"ZAR\": 16.0224, \"AUD\": 1.5911, \"JPY\": 124.93, \"TRY\": 6.6913,\n",
    "                     \"HKD\": 8.8007, \"MYR\": 4.6314, \"THB\": 35.802, \"HRK\": 7.413, \"NOK\": 9.6678, \"IDR\": 15953.68,\n",
    "                     \"DKK\": 7.4646, \"CZK\": 25.659, \"HUF\": 322.97, \"GBP\": 0.86248, \"MXN\": 21.2829, \"KRW\": 1308.01,\n",
    "                     \"ISK\": 136.2, \"SGD\": 1.5263, \"BRL\": 4.405, \"PLN\": 4.2868, \"INR\": 78.0615, \"RON\": 4.7596,\n",
    "                     \"CNY\": 7.5541, \"SEK\": 10.635}\n",
    "    return row['amount'] / (currency_dict[row['currencycode']]*100)\n",
    "\n",
    "df1['amount_eur'] = df1.apply(lambda x: conv(x), axis=1)\n",
    "\n",
    "lb2 = LabelBinarizer()\n",
    "y = lb2.fit_transform(df1['txvariantcode'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'txvariantcode' column\n",
    "df2 = pd.DataFrame(y, columns=['txvariantcode_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'txvariantcode' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('txvariantcode', axis=1), df2], axis=1)\n",
    "\n",
    "lb3 = LabelBinarizer()\n",
    "y = lb3.fit_transform(df1['currencycode'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'currencycode' column\n",
    "df2 = pd.DataFrame(y, columns=['currencycode_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'currencycode' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('currencycode', axis=1), df2], axis=1)\n",
    "\n",
    "lb4 = LabelBinarizer()\n",
    "y = lb4.fit_transform(df1['shopperinteraction'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'shopperinteraction' column\n",
    "df2 = pd.DataFrame(y, columns=['shopperinteraction_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'shopperinteraction' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('shopperinteraction', axis=1), df2], axis=1)\n",
    "\n",
    "df1['accountcode'] = df1['accountcode'].apply(lambda x: re.sub('Account','',x))\n",
    "df1['accountcode_cc'] = 0\n",
    "df1.loc[(df1['accountcode'] == 'UK'),'accountcode_cc'] = 'GB'\n",
    "df1.loc[(df1['accountcode'] == 'Mexico'),'accountcode_cc'] = 'MX'\n",
    "df1.loc[(df1['accountcode'] == 'Sweden'),'accountcode_cc'] = 'SE'\n",
    "df1.loc[(df1['accountcode'] == 'APAC'),'accountcode_cc'] = 'APAC'\n",
    "\n",
    "lb5 = LabelBinarizer()\n",
    "y = lb5.fit_transform(df1['accountcode_cc'])\n",
    "\n",
    "# Create a new DataFrame with the transformed 'accountcode_cc' column\n",
    "df2 = pd.DataFrame(y, columns=['accountcode_cc_'+str(i) for i in range(y.shape[1])])\n",
    "\n",
    "# Replace the 'accountcode_cc' column in the original DataFrame with the transformed column\n",
    "df1 = pd.concat([df1.drop('accountcode_cc', axis=1), df2], axis=1)\n",
    "\n",
    "df1.loc[df1['mail_id'].str.contains('na',case=False),'mail_id'] = 'email99999'\n",
    "\n",
    "df1.loc[df1['cvcresponsecode'] > 2,'cvcresponsecode'] = 3\n",
    "\n",
    "\n",
    "# X = df1[['issuercountrycode','txvariantcode','bin','amount','currencycode','shoppercountrycode','shopperinteraction','cardverificationcodesupplied','cvcresponsecode','accountcode','mail_id','ip_id','card_id','amount_eur','countries_equal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop id, mail_id, ip_id, card_id\n",
    "df1 = df1.drop(['Id','mail_id','ip_id','card_id', 'amount', 'accountcode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Preprocess your dataset here (e.g., encode categorical variables, scale numerical variables, etc.)\n",
    "\n",
    "# # Separate features and labels\n",
    "# X = df1.drop('label', axis=1)\n",
    "# y = df1['label']\n",
    "\n",
    "# # Split the dataset into a training set (80%) and a testing set (20%)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)# # # # # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and train the Decision Tree Classifier\n",
    "# clf = DecisionTreeClassifier(random_state=42)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # Print the classification report and accuracy\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use a neural network for classification\n",
    "# # Create and train the Multi-Layer Perceptron Classifier\n",
    "# clf = MLPClassifier(random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # Print the classification report and accuracy\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([     1,      2,      3,      5,      6,      7,      9,     10,\\n                11,     12,\\n            ...\\n            189618, 189619, 189620, 189621, 189622, 189623, 189624, 189625,\\n            189626, 189627],\\n           dtype='int64', length=151702)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# Iterate through the folds\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m skf\u001b[39m.\u001b[39msplit(X, y):\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Split the data into training and test sets for the current fold\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     X_train, X_test \u001b[39m=\u001b[39m X[train_index], X[test_index]\n\u001b[1;32m     20\u001b[0m     y_train, y_test \u001b[39m=\u001b[39m y[train_index], y[test_index]\n\u001b[1;32m     22\u001b[0m     \u001b[39m# Create and train the Decision Tree Classifier\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([     1,      2,      3,      5,      6,      7,      9,     10,\\n                11,     12,\\n            ...\\n            189618, 189619, 189620, 189621, 189622, 189623, 189624, 189625,\\n            189626, 189627],\\n           dtype='int64', length=151702)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X = df1.drop('label', axis=1)\n",
    "y = df1['label']\n",
    "\n",
    "# Define the number of folds\n",
    "n_splits = 5\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize accuracy lists to store accuracy for each fold for each classifier\n",
    "accuracy_list_decision_tree = []\n",
    "accuracy_list_mlp = []\n",
    "\n",
    "\n",
    "# Iterate through the folds\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and test sets for the current fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Create and train the Decision Tree Classifier\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy and add it to the accuracy_list\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list_decision_tree.append(accuracy)\n",
    "\n",
    "    # use a neural network for classification\n",
    "    # Create and train the Multi-Layer Perceptron Classifier\n",
    "    clf = MLPClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list_mlp.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy across all folds for decision tree\n",
    "average_accuracy = np.mean(accuracy_list_decision_tree)\n",
    "print(\"Average accuracy decision tree:\", average_accuracy)\n",
    "\n",
    "# Calculate the average accuracy across all folds for MLP\n",
    "average_accuracy = np.mean(accuracy_list_mlp)\n",
    "print(\"Average accuracy mlp:\", average_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
